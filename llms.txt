# Backpropagate

> Headless LLM fine-tuning in 3 lines of Python with GGUF export to Ollama.

## Purpose
Backpropagate wraps Unsloth/HuggingFace training into a minimal API. It handles VRAM auto-sizing, Windows quirks (multiprocessing, xformers), and multi-run SLAO training to prevent catastrophic forgetting. Export to GGUF and register with Ollama in one call.

## Quickstart
```bash
pip install backpropagate[standard]
```
```python
from backpropagate import Trainer
trainer = Trainer("unsloth/Qwen2.5-7B-Instruct-bnb-4bit")
trainer.train("my_data.jsonl", steps=100)
trainer.export("gguf", quantization="q4_k_m")
```

## Key API (Python)
- `Trainer(model, lora_r=16, lora_alpha=32, learning_rate=2e-4, batch_size="auto")`
- `trainer.train(dataset, steps=100, samples=1000)` -> `TrainingRun`
- `trainer.save(path)` -- save LoRA adapter
- `trainer.export(format, quantization)` -- export to GGUF
- `trainer.multi_run(dataset, num_runs=5, steps_per_run=100, merge_mode="slao")` -- multi-run SLAO
- `register_with_ollama(gguf_path, name)` -- register model with Ollama
- `check_gpu_safe()` / `get_gpu_status()` / `GPUMonitor` -- GPU health monitoring

## Key CLI Commands
- `backprop train --data <file> --model <name> --steps N`
- `backprop multi-run --data <file> --runs N --steps N`
- `backprop export <path> --format gguf --quantization q4_k_m --ollama --ollama-name <name>`
- `backprop info` -- system info and feature detection
- `backpropagate --ui` -- launch Gradio web UI

## Constraints
- Requires CUDA GPU (8GB+ VRAM recommended); CPU-only not supported
- Python 3.10+, PyTorch 2.0+
- Modular installs: `[unsloth]`, `[ui]`, `[validation]`, `[export]`, `[monitoring]`, `[standard]`, `[full]`
- Windows auto-fixes: pre-tokenization, xformers disable for RTX 40/50 series
- Dataset format: JSONL with `text` field or HuggingFace dataset with `text` column
- Config via env vars (`BACKPROPAGATE_MODEL__NAME`, etc.) or `.env` file

## Links
- Repo: https://github.com/mcp-tool-shop/backpropagate
- PyPI: https://pypi.org/project/backpropagate/
